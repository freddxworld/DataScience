{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04253cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f485c672",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"healthcare-dataset-stroke-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d3add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type','avg_glucose_level', 'bmi', 'smoking_status', 'stroke']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b01a4",
   "metadata": {},
   "source": [
    "##### Handling the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1089a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bmi'] = df['bmi'].apply(lambda x: 47 if x > 47 else x)\n",
    "df['avg_glucose_level'] = df['avg_glucose_level'].apply(lambda x: 170 if x > 170 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84911a1",
   "metadata": {},
   "source": [
    "#### Handling the null values for BMI  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8258106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on the plot for bmi we can see that it is not normally distributed so we will be filling in the missing values using \n",
    "#the medium\n",
    "df['bmi'] = df['bmi'].fillna(df['bmi'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2805cc16",
   "metadata": {},
   "source": [
    "#### Transform the variables that are an object datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a7eaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd59e0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we do label encoding on these columns\n",
    "df['gender'] = le.fit_transform(df['gender'])\n",
    "df['ever_married'] = le.fit_transform(df['ever_married'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5497c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the hot encoder for work type, residence type, and smoking status since, they are not ordinal we \n",
    "#cant jsut integer encode it we have to use a different method\n",
    "#like one hot encoding\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder_df = pd.DataFrame(encoder.fit_transform(df[['work_type']]).toarray())\n",
    "df = df.join(encoder_df)\n",
    "df.rename(columns = {0:'Private', 1:'Self-employed', 2:'Govt_job', 3:'children', 4:'Never_worked'}, inplace = True)\n",
    "encoder_df2 = pd.DataFrame(encoder.fit_transform(df[['Residence_type']]).toarray())\n",
    "df = df.join(encoder_df2)\n",
    "df.rename(columns = {0:'Urban', 1:'Rural'}, inplace = True)\n",
    "encoder_df3 = pd.DataFrame(encoder.fit_transform(df[['smoking_status']]).toarray())\n",
    "df = df.join(encoder_df3)\n",
    "df.rename(columns = {0:'formerly smoked', 1:'never smoked', 2:'smokes', 3:'Unknown'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c38bca4",
   "metadata": {},
   "source": [
    "### Createing input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c0603",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[[ 'age', 'gender', 'bmi', 'hypertension', 'heart_disease', 'ever_married', 'avg_glucose_level', 'Private', 'Self-employed', 'Govt_job', 'children', 'Never_worked', 'Urban', 'Rural', 'formerly smoked', 'never smoked', 'smokes', 'Unknown']]\n",
    "y = df[['stroke']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c86dd5",
   "metadata": {},
   "source": [
    "### Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ab772f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#graph to see the feature correlation\n",
    "corrmat = df.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize = (20,20))\n",
    "g=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e1e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the selectkbest\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(x,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(x.columns)\n",
    "#creates a quick graph to show the features and their score\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Features','Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ee5f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14cec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(featureScores.nlargest(10,'Score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18afc249",
   "metadata": {},
   "source": [
    "### Standarizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4615daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler().fit(df)\n",
    "#sD = scaler.transform(df)\n",
    "#sD = pd.DataFrame(sD, index=df.index,columns=df.columns)\n",
    "scaler = StandardScaler()\n",
    "df[['age', 'avg_glucose_level','bmi']] = scaler.fit_transform(df[['age','avg_glucose_level','bmi']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e65066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize columns A and B\n",
    "df[['age', 'avg_glucose_level', 'bmi']] = df[['age', 'avg_glucose_level', 'bmi']].apply(lambda x: x/x.max(), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e2ff0a",
   "metadata": {},
   "source": [
    "### moving our dataframe into input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae4431",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be900c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b2d2d3",
   "metadata": {},
   "source": [
    "### Dropping columns that are not needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d389021",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.drop(['gender'], axis = 1)\n",
    "x = x.drop(['Private'], axis = 1)\n",
    "x = x.drop([ 'Self-employed' ], axis = 1)\n",
    "x = x.drop(['Govt_job' ], axis = 1)\n",
    "x = x.drop(['smokes'], axis = 1)\n",
    "x = x.drop(['Unknown'  ], axis = 1)\n",
    "x = x.drop(['work_type'], axis = 1)\n",
    "x = x.drop(['Residence_type'  ], axis = 1)\n",
    "x = x.drop(['smoking_status'  ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21bf5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e6be2a",
   "metadata": {},
   "source": [
    "### splitting our data into test and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a311b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aaa1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test['stroke'].values\n",
    "y_train = y_train['stroke'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcf7334",
   "metadata": {},
   "source": [
    "### applying SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27752cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\t Pre oversampling, the shape of x_train:{}\".format(x_train.shape))\n",
    "#print(\"\\n\\t Pre oversampling, the shape of y_train:{}\".format(y_transTrain.shape))\n",
    "print(\"\\n\\t Pre oversampling, the shape of y_train:{}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacce6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pre OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) \n",
    "#print(\"Pre OverSampling, counts of label '0': {}\".format(sum(y_transTrain== 0)\n",
    "print(\"Pre OverSampling, counts of label '0': {}\".format(sum(y_train == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858772d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(sampling_strategy = 0.3, k_neighbors = 5, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316e02da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_res, y_train_res = sm.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f43b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\t Post oversampling, the shape of x_train_res:{}\".format(x_train_res.shape))\n",
    "print(\"\\n\\t Post oversampling, the shape of y_train_res:{}\".format(y_train_res.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af860cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb23208",
   "metadata": {},
   "source": [
    "### Building a Logistic Regression Model Using Training Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df47016",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e208e068",
   "metadata": {},
   "source": [
    "#### Predicting accuracy score for testing data  and training to compare and other scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce40af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredTest = model.predict(x_test)\n",
    "LogisticRegs, LogisticRegt, _ = roc_curve(y_test, ypredTest)\n",
    "accuracyTest = accuracy_score(y_test, ypredTest)\n",
    "print(\"accuracy for model on testing data is:\", accuracyTest.round(4))\n",
    "ypredTrain = model.predict(x_train_res)\n",
    "accuracyTrain = accuracy_score(y_train_res, ypredTrain)\n",
    "print(\"accuracy for model on training data is:\", accuracyTrain.round(2))\n",
    "auc_roc = roc_auc_score(y_test, ypredTest)\n",
    "print('AUC-ROC score:', auc_roc)\n",
    "f_score = f1_score(y_test, ypredTest)\n",
    "print('F-score :', f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7d737",
   "metadata": {},
   "source": [
    "### Building a Naive Bayes Model using the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e908158",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33882a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.fit(x_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93850001",
   "metadata": {},
   "source": [
    "#### Predicting accuracy score for testing data  and training to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb4a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredTest2 = nb_model.predict(x_test)\n",
    "accuracyTest2 = accuracy_score(y_test, ypredTest2)\n",
    "print(\"accuracy for model on testing data is:\", accuracyTest2.round(2))\n",
    "NaiveBr, NaiveBm, _ = roc_curve(y_test, ypredTest2)\n",
    "y_predTrain2 = nb_model.predict(x_train_res)\n",
    "accuracyTrain2 = accuracy_score(y_train_res, y_predTrain2)\n",
    "print(\"accuracy for model on training data is:\", accuracyTrain2.round(2))\n",
    "f2_score = f1_score(y_test, ypredTest2)\n",
    "print('F-score:', f_score)\n",
    "auc_roc = roc_auc_score(y_test, ypredTest2)\n",
    "print('AUC-ROC score:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04fec27",
   "metadata": {},
   "source": [
    "### Building a K-Nearest Neighbor Classifier model using Training Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e12a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e67bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the training data\n",
    "knn.fit(x_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abeeb74",
   "metadata": {},
   "source": [
    "#### Predicting accuracy score for testing data  and training to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ae907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing data\n",
    "ypredTest3 = knn.predict(x_test)\n",
    "KNearr, KNeart, _ = roc_curve(y_test, ypredTest3)\n",
    "accuracyTest3 = accuracy_score(y_test, ypredTest3)\n",
    "print(\"accuracy for model on testing data is:\", accuracyTest3.round(3))\n",
    "# Make predictions on the training data\n",
    "ypredTrain3 = knn.predict(x_train_res)\n",
    "accuracyTrain3 = accuracy_score(y_train_res, ypredTrain3)\n",
    "print(\"accuracy for model on training data is:\", accuracyTrain3.round(3))\n",
    "f2_score = f1_score(y_test, ypredTest3)\n",
    "auc_roc = roc_auc_score(y_test, ypredTest3)\n",
    "print('AUC-ROC:', auc_roc)\n",
    "print('F-score:', f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268187a8",
   "metadata": {},
   "source": [
    "### Build a  Support Vector Machine Classifier model using the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e221259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "# Train the model on the training data\n",
    "svm.fit(x_train_res, y_train_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd2d54",
   "metadata": {},
   "source": [
    "#### Predicting accuracy score for testing data  and training to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf8e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing data\n",
    "ypredTest4 = svm.predict(x_test)\n",
    "SVectorr, SVectort, _ = roc_curve(y_test, ypredTest4)\n",
    "accuracyTest4 = accuracy_score(y_test, ypredTest4)\n",
    "print(\"accuracy for model on testing data is:\", accuracyTest4.round(2))\n",
    "# Make predictions on the training data\n",
    "ypredTrain4 = svm.predict(x_train_res)\n",
    "accuracyTrain4 = accuracy_score(y_train_res, ypredTrain4)\n",
    "print(\"accuracy for model on training data is:\", accuracyTrain4.round(2))\n",
    "f2_score = f1_score(y_test, ypredTest4)\n",
    "auc_roc = roc_auc_score(y_test, ypredTest4)\n",
    "print('AUC-ROC score:', auc_roc)\n",
    "print('F-score:', f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9e1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(LogisticRegs, LogisticRegt, label='Logistic Regression')\n",
    "plt.plot(NaiveBr,NaiveBm, label=\"Naive Bayes\")\n",
    "plt.plot(KNearr,KNeart, label=\"K Neareast\")\n",
    "plt.plot(SVectorr,SVectort, label=\"Support Vector Machine\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
